{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b260fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssupa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.0)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9cfe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH   = \"../data/CLEAN_BIGGEST_CHUNK-weather-PM2.5-data/weather-PM2.5-05T.csv\"  # <- แก้ path ได้\n",
    "DATE_COL   = \"Date\"\n",
    "TARGET_COL = \"PM2.5\"\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "# Feature engineering\n",
    "LAGS = [1, 2, 3, 7, 14, 30]\n",
    "ROLL_WINDOWS = [3, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857869ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Parse date (ของคุณเป็น m/d/YYYY ในตัวอย่าง)\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL], format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "\n",
    "    # Convert numeric cols\n",
    "    for c in df.columns:\n",
    "        if c != DATE_COL:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[DATE_COL])\n",
    "    df = df.sort_values(DATE_COL).drop_duplicates(subset=[DATE_COL]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"year\"] = df[DATE_COL].dt.year\n",
    "    df[\"month\"] = df[DATE_COL].dt.month\n",
    "    df[\"dayofweek\"] = df[DATE_COL].dt.dayofweek\n",
    "    df[\"dayofyear\"] = df[DATE_COL].dt.dayofyear\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_lag_and_rolling(df: pd.DataFrame, target_col: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # lag features (past only)\n",
    "    for lag in LAGS:\n",
    "        df[f\"{target_col}_lag{lag}\"] = df[target_col].shift(lag)\n",
    "\n",
    "    # rolling features (past only) -> shift(1) before rolling\n",
    "    for w in ROLL_WINDOWS:\n",
    "        s = df[target_col].shift(1)\n",
    "        df[f\"{target_col}_rollmean{w}\"] = s.rolling(window=w, min_periods=1).mean()\n",
    "        df[f\"{target_col}_rollstd{w}\"]  = s.rolling(window=w, min_periods=2).std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673ec1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of            Date  Wind Speed  Temp.  Humi.  heatidx   Pres.  Prec.   Vis.  \\\n",
       "0    2018-04-10         3.2   30.4   69.7     36.0  1009.3    0.0  16207   \n",
       "1    2018-04-11         4.5   30.2   79.1     38.0  1008.5    0.0  17389   \n",
       "2    2018-04-12         4.8   30.3   78.9     38.1  1008.2    0.0  18160   \n",
       "3    2018-04-13         4.8   30.5   79.7     39.2  1008.3    0.0  17780   \n",
       "4    2018-04-14         5.0   30.6   79.5     39.4  1007.6    0.0  19379   \n",
       "...         ...         ...    ...    ...      ...     ...    ...    ...   \n",
       "2059 2024-09-23         2.5   29.3   72.3     33.8  1007.7    7.2  17307   \n",
       "2060 2024-09-24         1.4   26.9   81.3     29.7  1009.1   40.2  17298   \n",
       "2061 2024-09-25         1.2   27.5   80.0     30.8  1009.5   15.6  17275   \n",
       "2062 2024-09-26         1.5   29.1   74.0     33.8  1009.0    6.4  17289   \n",
       "2063 2024-09-27         1.8   29.0   74.5     33.6  1008.6    2.4  17295   \n",
       "\n",
       "      PM2.5  year  ...  PM2.5_lag7  PM2.5_lag14  PM2.5_rollmean3  \\\n",
       "0     43.00  2018  ...         NaN          NaN              NaN   \n",
       "1     19.00  2018  ...         NaN          NaN        43.000000   \n",
       "2     11.00  2018  ...         NaN          NaN        31.000000   \n",
       "3      9.00  2018  ...         NaN          NaN        24.333333   \n",
       "4      9.00  2018  ...         NaN          NaN        13.000000   \n",
       "...     ...   ...  ...         ...          ...              ...   \n",
       "2059  13.10  2024  ...        24.6         15.3        14.166667   \n",
       "2060  13.70  2024  ...        23.8         17.5        13.500000   \n",
       "2061  20.00  2024  ...        20.7         16.4        13.533333   \n",
       "2062  24.35  2024  ...        20.4         18.4        15.600000   \n",
       "2063  28.70  2024  ...        15.1         17.6        19.350000   \n",
       "\n",
       "      PM2.5_rollstd3  PM2.5_rollmean7  PM2.5_rollstd7  PM2.5_rollmean14  \\\n",
       "0                NaN              NaN             NaN               NaN   \n",
       "1                NaN        43.000000             NaN         43.000000   \n",
       "2          16.970563        31.000000       16.970563         31.000000   \n",
       "3          16.653328        24.333333       16.653328         24.333333   \n",
       "4           5.291503        20.500000       15.609826         20.500000   \n",
       "...              ...              ...             ...               ...   \n",
       "2059        0.814453        18.857143        4.663996         17.878571   \n",
       "2060        0.360555        17.214286        4.316414         17.721429   \n",
       "2061        0.378594        15.771429        3.321503         17.450000   \n",
       "2062        3.822303        15.671429        3.154739         17.707143   \n",
       "2063        5.354671        16.235714        4.290369         18.132143   \n",
       "\n",
       "      PM2.5_rollstd14  Wind Dir_sin  Wind Dir_cos  \n",
       "0                 NaN  1.224647e-16     -1.000000  \n",
       "1                 NaN -2.249511e-01     -0.974370  \n",
       "2           16.970563 -2.079117e-01     -0.978148  \n",
       "3           16.653328 -2.419219e-01     -0.970296  \n",
       "4           15.609826 -1.908090e-01     -0.981627  \n",
       "...               ...           ...           ...  \n",
       "2059         3.414039  3.746066e-01     -0.927184  \n",
       "2060         3.588053  9.702957e-01     -0.241922  \n",
       "2061         3.746332  9.205049e-01     -0.390731  \n",
       "2062         3.791988  9.902681e-01      0.139173  \n",
       "2063         4.188336  8.191520e-01     -0.573576  \n",
       "\n",
       "[2064 rows x 29 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_wind_dir_sincos_deg(\n",
    "    df: pd.DataFrame,\n",
    "    wind_dir_col: str,\n",
    "    drop_original: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # แปลงเป็นตัวเลขก่อน (เผื่อมี string)\n",
    "    wd = pd.to_numeric(df[wind_dir_col], errors=\"coerce\")\n",
    "\n",
    "    # ทำให้อยู่ในช่วง 0..360 (กันค่าหลุด เช่น -10, 370)\n",
    "    wd = wd % 360\n",
    "\n",
    "    rad = np.deg2rad(wd)  # degrees -> radians\n",
    "\n",
    "    df[f\"{wind_dir_col}_sin\"] = np.sin(rad)\n",
    "    df[f\"{wind_dir_col}_cos\"] = np.cos(rad)\n",
    "\n",
    "    if drop_original and wind_dir_col in df.columns:\n",
    "        df = df.drop(columns=[wind_dir_col])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_time_features(\n",
    "    df: pd.DataFrame,\n",
    "    drop_original: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"year\"] = df[DATE_COL].dt.year\n",
    "\n",
    "    # month: 1..12 -> 0..11\n",
    "    m = df[DATE_COL].dt.month - 1\n",
    "    df[\"month_sin\"] = np.sin(2*np.pi*m/12)\n",
    "    df[\"month_cos\"] = np.cos(2*np.pi*m/12)\n",
    "\n",
    "    # dayofweek: 0..6\n",
    "    dow = df[DATE_COL].dt.dayofweek\n",
    "    df[\"dayofweek_sin\"] = np.sin(2*np.pi*dow/7)\n",
    "    df[\"dayofweek_cos\"] = np.cos(2*np.pi*dow/7)\n",
    "\n",
    "    # dayofyear: 1..365/366 -> ใช้จำนวนวันจริงของปีนั้น\n",
    "    doy0 = df[DATE_COL].dt.dayofyear - 1\n",
    "    days_in_year = df[DATE_COL].dt.is_leap_year.map({True: 366, False: 365}).astype(int)\n",
    "    df[\"dayofyear_sin\"] = np.sin(2*np.pi*doy0/days_in_year)\n",
    "    df[\"dayofyear_cos\"] = np.cos(2*np.pi*doy0/days_in_year)\n",
    "\n",
    "    # ถ้าคุณเคยสร้าง month/dayofweek/dayofyear ไว้แล้วในขั้นก่อนหน้า -> ลบทิ้ง\n",
    "    if drop_original:\n",
    "        cols_to_drop = [c for c in [\"month\", \"dayofweek\", \"dayofyear\"] if c in df.columns]\n",
    "        if cols_to_drop:\n",
    "            df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_and_clean(CSV_PATH)\n",
    "df = add_time_features(df, drop_original=True)\n",
    "df = add_lag_and_rolling(df, target_col=TARGET_COL)\n",
    "df = add_wind_dir_sincos_deg(df, wind_dir_col=\"Wind Dir\", drop_original=True)\n",
    "\n",
    "df.tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a800a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD = c:\\Users\\ssupa\\Code\\Pm2.5_forcast\\cleaning_code\n",
      "Will save to = C:\\Users\\ssupa\\Code\\Pm2.5_forcast\\data\\cleaned_features.csv\n"
     ]
    }
   ],
   "source": [
    "def safe_to_csv(df: pd.DataFrame, out_path: str, index: bool = False, encoding: str = \"utf-8-sig\") -> None:\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # สร้างไฟล์ชั่วคราวในโฟลเดอร์เดียวกัน (กันปัญหา cross-device)\n",
    "    fd, tmp_path = tempfile.mkstemp(prefix=out_path.stem + \".\", suffix=\".tmp\", dir=str(out_path.parent))\n",
    "    os.close(fd)  # ปิด handle ทันที (ให้ pandas เขียนเอง)\n",
    "\n",
    "    try:\n",
    "        df.to_csv(tmp_path, index=index, encoding=encoding)\n",
    "        os.replace(tmp_path, out_path)  # atomic replace (ทับไฟล์เดิมแบบปลอดภัย)\n",
    "    finally:\n",
    "        # ถ้าเกิด error และ tmp ยังอยู่ ให้ลบ\n",
    "        if os.path.exists(tmp_path):\n",
    "            try:\n",
    "                os.remove(tmp_path)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "print(\"CWD =\", os.getcwd())\n",
    "print(\"Will save to =\", Path(r\"../data/cleaned_features.csv\").resolve())            \n",
    "safe_to_csv(df, r\"../data/cleaned_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb472720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target = C:\\Users\\ssupa\\Code\\Pm2.5_forcast\\cleaning_code\\Data\\cleaned_features.csv\n",
      "exists = False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "p = Path(r\"../data/cleaned_features.csv\").resolve()\n",
    "print(\"target =\", p)\n",
    "print(\"exists =\", p.exists())\n",
    "if p.exists():\n",
    "    print(\"size =\", p.stat().st_size, \"bytes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

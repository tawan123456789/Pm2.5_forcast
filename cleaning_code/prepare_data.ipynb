{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b260fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssupa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.0)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9cfe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH   = \"../data/CLEAN_BIGGEST_CHUNK-weather-PM2.5-data/weather-PM2.5-44T.csv\"  # <- แก้ path ได้\n",
    "DATE_COL   = \"Date\"\n",
    "TARGET_COL = \"PM2.5\"\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "# Feature engineering\n",
    "LAGS = [1, 2, 3, 7, 14, 30]\n",
    "ROLL_WINDOWS = [3, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857869ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    # Parse date (ของคุณเป็น m/d/YYYY ในตัวอย่าง)\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "    # Convert numeric cols\n",
    "    for c in df.columns:\n",
    "        if c != DATE_COL:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[DATE_COL])\n",
    "    df = df.sort_values(DATE_COL).drop_duplicates(subset=[DATE_COL]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"year\"] = df[DATE_COL].dt.year\n",
    "    df[\"month\"] = df[DATE_COL].dt.month\n",
    "    df[\"dayofweek\"] = df[DATE_COL].dt.dayofweek\n",
    "    df[\"dayofyear\"] = df[DATE_COL].dt.dayofyear\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_lag_and_rolling(df: pd.DataFrame, target_col: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # lag features (past only)\n",
    "    for lag in LAGS:\n",
    "        df[f\"{target_col}_lag{lag}\"] = df[target_col].shift(lag)\n",
    "\n",
    "    # rolling features (past only) -> shift(1) before rolling\n",
    "    for w in ROLL_WINDOWS:\n",
    "        s = df[target_col].shift(1)\n",
    "        df[f\"{target_col}_rollmean{w}\"] = s.rolling(window=w, min_periods=1).mean()\n",
    "        df[f\"{target_col}_rollstd{w}\"]  = s.rolling(window=w, min_periods=2).std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "673ec1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of            Date  Wind Speed  Temp.  Humi.  heatidx   Pres.  Prec.  Vis.  \\\n",
       "0    2012-06-25         1.5   27.4   77.9     30.4     0.0    1.4   NaN   \n",
       "1    2012-06-30         3.0   29.1   68.6     32.6  1005.5    0.0   NaN   \n",
       "2    2012-07-01         1.7   28.3   73.3     31.7  1005.8    0.0   NaN   \n",
       "3    2012-07-02         2.5   27.7   72.3     30.5  1005.9    0.0   NaN   \n",
       "4    2012-07-06         2.3   27.4   73.2     29.9  1005.6    0.0   NaN   \n",
       "...         ...         ...    ...    ...      ...     ...    ...   ...   \n",
       "1263 2025-06-26         1.6   30.6   75.5     38.1  1007.1    0.4   NaN   \n",
       "1264 2025-06-27         0.0   27.8   83.1     32.1  1008.2    0.0   NaN   \n",
       "1265 2025-06-28         0.0   27.4   85.4     31.2  1006.6    0.0   NaN   \n",
       "1266 2025-06-29         2.4   29.2   79.3     35.1  1006.0    0.0   NaN   \n",
       "1267 2025-06-30         3.8   31.2   68.7     37.8  1006.2    0.0   NaN   \n",
       "\n",
       "      PM2.5  year  ...  Prec._lag2  Prec._lag3  Prec._lag7  Prec._lag14  \\\n",
       "0      26.0  2012  ...         NaN         NaN         NaN          NaN   \n",
       "1      22.0  2012  ...         NaN         NaN         NaN          NaN   \n",
       "2      36.0  2012  ...         1.4         NaN         NaN          NaN   \n",
       "3      36.0  2012  ...         0.0         1.4         NaN          NaN   \n",
       "4      20.0  2012  ...         0.0         0.0         NaN          NaN   \n",
       "...     ...   ...  ...         ...         ...         ...          ...   \n",
       "1263   16.7  2025  ...         9.8         6.0         0.0          0.0   \n",
       "1264   16.3  2025  ...         0.0         9.8        18.6          0.0   \n",
       "1265   16.8  2025  ...         0.4         0.0         2.2          0.0   \n",
       "1266   15.0  2025  ...         0.0         0.4         0.2          0.0   \n",
       "1267   14.8  2025  ...         0.0         0.0         6.0          4.8   \n",
       "\n",
       "      Prec._rollsum3  Prec._rollmean3  Prec._rollsum7  Prec._rollmean7  \\\n",
       "0                NaN              NaN             NaN              NaN   \n",
       "1                1.4         1.400000             1.4         1.400000   \n",
       "2                1.4         0.700000             1.4         0.700000   \n",
       "3                1.4         0.466667             1.4         0.466667   \n",
       "4                0.0         0.000000             1.4         0.350000   \n",
       "...              ...              ...             ...              ...   \n",
       "1263            15.8         5.266667            36.8         5.257143   \n",
       "1264            10.2         3.400000            37.2         5.314286   \n",
       "1265             0.4         0.133333            18.6         2.657143   \n",
       "1266             0.4         0.133333            16.4         2.342857   \n",
       "1267             0.0         0.000000            16.2         2.314286   \n",
       "\n",
       "      Prec._rollsum14  Prec._rollmean14  \n",
       "0                 NaN               NaN  \n",
       "1                 1.4          1.400000  \n",
       "2                 1.4          0.700000  \n",
       "3                 1.4          0.466667  \n",
       "4                 1.4          0.350000  \n",
       "...               ...               ...  \n",
       "1263             58.6          4.185714  \n",
       "1264             59.0          4.214286  \n",
       "1265             59.0          4.214286  \n",
       "1266             59.0          4.214286  \n",
       "1267             59.0          4.214286  \n",
       "\n",
       "[1268 rows x 41 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_wind_dir_sincos_deg(\n",
    "    df: pd.DataFrame,\n",
    "    wind_dir_col: str,\n",
    "    drop_original: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # แปลงเป็นตัวเลขก่อน (เผื่อมี string)\n",
    "    wd = pd.to_numeric(df[wind_dir_col], errors=\"coerce\")\n",
    "\n",
    "    # ทำให้อยู่ในช่วง 0..360 (กันค่าหลุด เช่น -10, 370)\n",
    "    wd = wd % 360\n",
    "\n",
    "    rad = np.deg2rad(wd)  # degrees -> radians\n",
    "\n",
    "    df[f\"{wind_dir_col}_sin\"] = np.sin(rad)\n",
    "    df[f\"{wind_dir_col}_cos\"] = np.cos(rad)\n",
    "\n",
    "    if drop_original and wind_dir_col in df.columns:\n",
    "        df = df.drop(columns=[wind_dir_col])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_time_features(\n",
    "    df: pd.DataFrame,\n",
    "    drop_original: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"year\"] = df[DATE_COL].dt.year\n",
    "\n",
    "    # month: 1..12 -> 0..11\n",
    "    m = df[DATE_COL].dt.month - 1\n",
    "    df[\"month_sin\"] = np.sin(2*np.pi*m/12)\n",
    "    df[\"month_cos\"] = np.cos(2*np.pi*m/12)\n",
    "\n",
    "    # dayofweek: 0..6\n",
    "    dow = df[DATE_COL].dt.dayofweek\n",
    "    df[\"dayofweek_sin\"] = np.sin(2*np.pi*dow/7)\n",
    "    df[\"dayofweek_cos\"] = np.cos(2*np.pi*dow/7)\n",
    "\n",
    "    # dayofyear: 1..365/366 -> ใช้จำนวนวันจริงของปีนั้น\n",
    "    doy0 = df[DATE_COL].dt.dayofyear - 1\n",
    "    days_in_year = df[DATE_COL].dt.is_leap_year.map({True: 366, False: 365}).astype(int)\n",
    "    df[\"dayofyear_sin\"] = np.sin(2*np.pi*doy0/days_in_year)\n",
    "    df[\"dayofyear_cos\"] = np.cos(2*np.pi*doy0/days_in_year)\n",
    "\n",
    "    # ถ้าคุณเคยสร้าง month/dayofweek/dayofyear ไว้แล้วในขั้นก่อนหน้า -> ลบทิ้ง\n",
    "    if drop_original:\n",
    "        cols_to_drop = [c for c in [\"month\", \"dayofweek\", \"dayofyear\"] if c in df.columns]\n",
    "        if cols_to_drop:\n",
    "            df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    return df\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def add_precip_lag_and_rolling(\n",
    "    df: pd.DataFrame,\n",
    "    precip_col: str = \"Prec.\",\n",
    "    lags=(1, 2, 3, 7, 14),\n",
    "    roll_windows=(3, 7, 14),\n",
    "    add_roll_sum: bool = True,\n",
    "    add_roll_mean: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # ---- lag features (past only) ----\n",
    "    for lag in lags:\n",
    "        df[f\"{precip_col}_lag{lag}\"] = df[precip_col].shift(lag)\n",
    "\n",
    "    # ---- rolling features (past only) ----\n",
    "    # ใช้ฝนในอดีตเท่านั้น: shift(1) ก่อน rolling\n",
    "    s = df[precip_col].shift(1)\n",
    "\n",
    "    for w in roll_windows:\n",
    "        if add_roll_sum:\n",
    "            df[f\"{precip_col}_rollsum{w}\"] = s.rolling(window=w, min_periods=1).sum()\n",
    "        if add_roll_mean:\n",
    "            df[f\"{precip_col}_rollmean{w}\"] = s.rolling(window=w, min_periods=1).mean()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_and_clean(CSV_PATH)\n",
    "df = add_time_features(df, drop_original=True)\n",
    "\n",
    "df = add_lag_and_rolling(df, target_col=TARGET_COL)\n",
    "df = add_wind_dir_sincos_deg(df, wind_dir_col=\"Wind Dir\", drop_original=True)\n",
    "\n",
    "# เพิ่ม lag/rolling ของฝน\n",
    "df = add_precip_lag_and_rolling(df, precip_col=\"Prec.\", lags=(1,2,3,7,14), roll_windows=(3,7,14))\n",
    "\n",
    "\n",
    "df.tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a800a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD = c:\\Users\\ssupa\\Code\\Pm2.5_forcast\\cleaning_code\n",
      "Will save to = C:\\Users\\ssupa\\Code\\Pm2.5_forcast\\data\\cleaned_features.csv\n"
     ]
    }
   ],
   "source": [
    "def safe_to_csv(df: pd.DataFrame, out_path: str, index: bool = False, encoding: str = \"utf-8-sig\") -> None:\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # สร้างไฟล์ชั่วคราวในโฟลเดอร์เดียวกัน (กันปัญหา cross-device)\n",
    "    fd, tmp_path = tempfile.mkstemp(prefix=out_path.stem + \".\", suffix=\".tmp\", dir=str(out_path.parent))\n",
    "    os.close(fd)  # ปิด handle ทันที (ให้ pandas เขียนเอง)\n",
    "\n",
    "    try:\n",
    "        df.to_csv(tmp_path, index=index, encoding=encoding)\n",
    "        os.replace(tmp_path, out_path)  \n",
    "    finally:\n",
    "        if os.path.exists(tmp_path):\n",
    "            try:\n",
    "                os.remove(tmp_path)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "print(\"CWD =\", os.getcwd())\n",
    "print(\"Will save to =\", Path(r\"../data/cleaned_features.csv\").resolve())            \n",
    "safe_to_csv(df, r\"../data/44T_cleaned_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb472720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target = C:\\Users\\ssupa\\Code\\Pm2.5_forcast\\data\\cleaned_features.csv\n",
      "exists = True\n",
      "size = 687992 bytes\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
